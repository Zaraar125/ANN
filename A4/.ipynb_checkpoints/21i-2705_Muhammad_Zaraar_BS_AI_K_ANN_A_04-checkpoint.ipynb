{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "bc8b1e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ec2792",
   "metadata": {},
   "source": [
    "# Class of Neural Network with Affine Layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "ecccdf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self):\n",
    "        self.temp=0\n",
    "        self.weights=[]\n",
    "        self.bias=[]\n",
    "        self.outputs=0\n",
    "        self.derivative_table=0\n",
    "        self.model_loss=100\n",
    "        self.local_derivatives=[]\n",
    "    def initialize_weights_and_bais(self,X,layers,neurons):\n",
    "        l=X.shape[1]\n",
    "        for i,j in enumerate(neurons):\n",
    "            self.weights.append(np.array([np.random.random(l) for k in range(j)]))\n",
    "            self.bias.append(np.round(np.random.random(j),6))\n",
    "            l=self.weights[i].shape[0]\n",
    "    def ReLU(self,INPUT):\n",
    "        INPUT[INPUT<0]=0\n",
    "        derr=np.zeros_like(INPUT)\n",
    "        derr[INPUT>0]=1\n",
    "        return INPUT,derr\n",
    "    def forward(self,X):\n",
    "        a=X\n",
    "        for i in range(len(self.weights)):\n",
    "            dw=a\n",
    "            a=np.dot(a,self.weights[i].T)+self.bias[i]\n",
    "            dx=self.weights[i]\n",
    "            db=np.ones(self.bias[i].shape)\n",
    "            if i!=len(self.weights)-1:\n",
    "                relu,relu_derr=self.ReLU(a)\n",
    "            else :\n",
    "                relu,relu_derr=np.array([0]),np.array([0])\n",
    "            self.local_derivatives.append([relu,dw,dx,db,relu_derr])\n",
    "            if i!=len(self.weights)-1:\n",
    "                a=relu\n",
    "        return a\n",
    "    \n",
    "    def loss(self,y,outputs):\n",
    "        self.derivative_table=outputs-outputs[np.arange(y.shape[0]),y].reshape(-1,1)\n",
    "        self.derivative_table[self.derivative_table<=0]=0\n",
    "        self.model_loss=np.sum(self.derivative_table)\n",
    "        self.derivative_table[self.derivative_table>0]=1\n",
    "        self.derivative_table[np.arange(y.shape[0]),y]=np.sum(self.derivative_table,axis=1)*-1\n",
    "        return self.derivative_table\n",
    "        \n",
    "    def backward(self,LR,output):\n",
    "        holding_weights=[]\n",
    "        holding_bias=[]\n",
    "        final_output=output\n",
    "        c=c=len(self.weights)-1\n",
    "        for i in reversed(self.local_derivatives):\n",
    "            if i[-1].shape[0]!=1:\n",
    "                final_ouput=np.multiply(final_output,i[-1])       \n",
    "            self.weights[c]=self.weights[c]-(LR*np.dot(final_output.T,i[1]))\n",
    "            self.bias[c]=self.bias[c]-(LR*np.sum(final_output,axis=0))\n",
    "            final_output=np.dot(final_output,i[2])\n",
    "            c=c-1\n",
    "            \n",
    "    def train(self,X,y,layers,neurons,LR=0.00001,iterations=50000,loss_time=1000):\n",
    "\n",
    "        self.initialize_weights_and_bais(X,layers,neurons)\n",
    "        for i in range(iterations):\n",
    "            OUT=self.forward(X)\n",
    "            DERR=self.loss(y,OUT)\n",
    "            self.backward(LR,DERR)\n",
    "\n",
    "            self.local_derivatives=[]            # empty local derivatives to calculate them again\n",
    "            if i%loss_time==0:\n",
    "                print('ITERATION : ',i,' MODEL LOSS : ',self.model_loss)\n",
    "    \n",
    "    def test(self,X,y):\n",
    "        temp=self.forward(X)\n",
    "        holder=[]\n",
    "        for i in temp:\n",
    "            i=list(i)\n",
    "            holder.append(i.index(max(i)))\n",
    "        tt = sum(1 for x, z in zip(holder, y) if x == z)\n",
    "        print((tt/len(holder))*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38074c03",
   "metadata": {},
   "source": [
    "# Preparing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "bf34bc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=datasets.load_iris()\n",
    "x,y,names=data['data'],data['target'],data[\"target_names\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2af90f6",
   "metadata": {},
   "source": [
    "# Splitting the Dataset into Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "a1fab90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.1,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56007ef",
   "metadata": {},
   "source": [
    "# Training the Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "cc096c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION :  0  MODEL LOSS :  1166.7120673995812\n",
      "ITERATION :  1000  MODEL LOSS :  0.16354813667851964\n",
      "ITERATION :  2000  MODEL LOSS :  0.14921086363036373\n",
      "ITERATION :  3000  MODEL LOSS :  0.14649155071445108\n",
      "ITERATION :  4000  MODEL LOSS :  0.1132650811778273\n",
      "ITERATION :  5000  MODEL LOSS :  0.05502376057547842\n",
      "ITERATION :  6000  MODEL LOSS :  0.06698813534461578\n",
      "ITERATION :  7000  MODEL LOSS :  0.22211736411795258\n",
      "ITERATION :  8000  MODEL LOSS :  0.12998500070926866\n",
      "ITERATION :  9000  MODEL LOSS :  0.047575416915815794\n",
      "ITERATION :  10000  MODEL LOSS :  0.05538721452437123\n",
      "ITERATION :  11000  MODEL LOSS :  0.04802723242737983\n",
      "ITERATION :  12000  MODEL LOSS :  0.0438136409694021\n",
      "ITERATION :  13000  MODEL LOSS :  0.042330972734140104\n",
      "ITERATION :  14000  MODEL LOSS :  0.05436447382033549\n",
      "ITERATION :  15000  MODEL LOSS :  0.07392832528306492\n",
      "ITERATION :  16000  MODEL LOSS :  0.03922943893791597\n",
      "ITERATION :  17000  MODEL LOSS :  0.04548875357826532\n",
      "ITERATION :  18000  MODEL LOSS :  0.033163223679567366\n",
      "ITERATION :  19000  MODEL LOSS :  0.045425702475803575\n",
      "ITERATION :  20000  MODEL LOSS :  0.06835156664962483\n",
      "ITERATION :  21000  MODEL LOSS :  0.030986254631823584\n",
      "ITERATION :  22000  MODEL LOSS :  0.032284009499012\n",
      "ITERATION :  23000  MODEL LOSS :  0.03148742404524896\n",
      "ITERATION :  24000  MODEL LOSS :  0.054918341757035805\n",
      "ITERATION :  25000  MODEL LOSS :  0.028003079904934225\n",
      "ITERATION :  26000  MODEL LOSS :  0.028952686739714295\n",
      "ITERATION :  27000  MODEL LOSS :  0.03237642646196015\n",
      "ITERATION :  28000  MODEL LOSS :  0.026995571452363087\n",
      "ITERATION :  29000  MODEL LOSS :  0.03561937892637346\n",
      "ITERATION :  30000  MODEL LOSS :  0.02522582535268203\n",
      "ITERATION :  31000  MODEL LOSS :  0.0702589637069373\n",
      "ITERATION :  32000  MODEL LOSS :  0.02593926305820382\n",
      "ITERATION :  33000  MODEL LOSS :  0.09446315505947744\n",
      "ITERATION :  34000  MODEL LOSS :  0.024001518196492988\n",
      "ITERATION :  35000  MODEL LOSS :  0.023260294453380403\n",
      "ITERATION :  36000  MODEL LOSS :  0.024121298492751464\n",
      "ITERATION :  37000  MODEL LOSS :  0.03047017606857061\n",
      "ITERATION :  38000  MODEL LOSS :  0.022273188071539884\n",
      "ITERATION :  39000  MODEL LOSS :  0.022574611957669966\n",
      "ITERATION :  40000  MODEL LOSS :  0.02344882658734626\n",
      "ITERATION :  41000  MODEL LOSS :  0.03337519732480487\n",
      "ITERATION :  42000  MODEL LOSS :  0.02158381330967707\n",
      "ITERATION :  43000  MODEL LOSS :  0.033354408162253435\n",
      "ITERATION :  44000  MODEL LOSS :  0.02144374560035711\n",
      "ITERATION :  45000  MODEL LOSS :  0.02002151296024479\n",
      "ITERATION :  46000  MODEL LOSS :  0.019955091968065553\n",
      "ITERATION :  47000  MODEL LOSS :  0.02746681511702498\n",
      "ITERATION :  48000  MODEL LOSS :  0.019204739539270044\n",
      "ITERATION :  49000  MODEL LOSS :  0.018543905587613096\n"
     ]
    }
   ],
   "source": [
    "a=NeuralNetwork()\n",
    "a.train(x_train,y_train,3,[5,7,3],0.0001,50000,1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2d7557",
   "metadata": {},
   "source": [
    "# Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "38027cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0\n"
     ]
    }
   ],
   "source": [
    "a.test(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898b675c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0b853d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
