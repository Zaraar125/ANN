{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc8b1e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ec2792",
   "metadata": {},
   "source": [
    "# Class of Neural Network with Affine Layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ecccdf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self):\n",
    "        self.temp=0\n",
    "        self.weights=[]\n",
    "        self.bias=[]\n",
    "        self.outputs=0\n",
    "        self.derivative_table=0\n",
    "        self.model_loss=100\n",
    "        self.local_derivatives=[]\n",
    "    def initialize_weights_and_bais(self,X,layers,neurons):\n",
    "        l=X.shape[1]\n",
    "        for i,j in enumerate(neurons):\n",
    "            self.weights.append(np.array([np.random.random(l) for k in range(j)]))\n",
    "            self.bias.append(np.round(np.random.random(j),6))\n",
    "            l=self.weights[i].shape[0]\n",
    "    def ReLU(self,INPUT):\n",
    "        INPUT[INPUT<0]=0\n",
    "        derr=np.zeros_like(INPUT)\n",
    "        derr[INPUT>0]=1\n",
    "        return INPUT,derr\n",
    "    def forward(self,X):\n",
    "        a=X\n",
    "        for i in range(len(self.weights)):\n",
    "            dw=a\n",
    "            a=np.dot(a,self.weights[i].T)+self.bias[i]\n",
    "            dx=self.weights[i]\n",
    "            db=np.ones(self.bias[i].shape)\n",
    "            if i!=len(self.weights)-1:\n",
    "                relu,relu_derr=self.ReLU(a)\n",
    "            else :\n",
    "                relu,relu_derr=np.array([0]),np.array([0])\n",
    "            self.local_derivatives.append([relu,dw,dx,db,relu_derr])\n",
    "#             if i!=len(self.weights)-1:\n",
    "#                 a=relu\n",
    "        return a\n",
    "    \n",
    "    def loss(self,y,outputs):\n",
    "        self.derivative_table=outputs-outputs[np.arange(y.shape[0]),y].reshape(-1,1)\n",
    "        self.derivative_table[self.derivative_table<=0]=0\n",
    "        self.model_loss=np.sum(self.derivative_table)\n",
    "        self.derivative_table[self.derivative_table>0]=1\n",
    "        self.derivative_table[np.arange(y.shape[0]),y]=np.sum(self.derivative_table,axis=1)*-1\n",
    "        return self.derivative_table\n",
    "        \n",
    "    def backward(self,LR,output):\n",
    "        holding_weights=[]\n",
    "        holding_bias=[]\n",
    "        final_output=output\n",
    "        c=c=len(self.weights)-1\n",
    "        for i in reversed(self.local_derivatives):\n",
    "            if i[-1].shape[0]!=1:\n",
    "                final_ouput=np.multiply(final_output,i[-1])       \n",
    "            self.weights[c]=self.weights[c]-(LR*np.dot(final_output.T,i[1]))\n",
    "            self.bias[c]=self.bias[c]-(LR*np.sum(final_output,axis=0))\n",
    "            final_output=np.dot(final_output,i[2])\n",
    "            c=c-1\n",
    "            \n",
    "    def train(self,X,y,layers,neurons,LR=0.00001,iterations=50000,loss_time=1000):\n",
    "\n",
    "        self.initialize_weights_and_bais(X,layers,neurons)\n",
    "        for i in range(iterations):\n",
    "            OUT=self.forward(X)\n",
    "            DERR=self.loss(y,OUT)\n",
    "            self.backward(LR,DERR)\n",
    "\n",
    "            self.local_derivatives=[]            # empty local derivatives to calculate them again\n",
    "            if i%loss_time==0:\n",
    "                print('ITERATION : ',i,' MODEL LOSS : ',self.model_loss)\n",
    "    \n",
    "    def test(self,X,y):\n",
    "        temp=self.forward(X)\n",
    "        holder=[]\n",
    "        for i in temp:\n",
    "            i=list(i)\n",
    "            holder.append(i.index(max(i)))\n",
    "        tt = sum(1 for x, z in zip(holder, y) if x == z)\n",
    "        print((tt/len(holder))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "742480e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('Housing.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "11759d76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>area</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>stories</th>\n",
       "      <th>mainroad</th>\n",
       "      <th>guestroom</th>\n",
       "      <th>basement</th>\n",
       "      <th>hotwaterheating</th>\n",
       "      <th>airconditioning</th>\n",
       "      <th>parking</th>\n",
       "      <th>prefarea</th>\n",
       "      <th>furnishingstatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13300000</td>\n",
       "      <td>7420</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12250000</td>\n",
       "      <td>8960</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12250000</td>\n",
       "      <td>9960</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>semi-furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12215000</td>\n",
       "      <td>7500</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "      <td>yes</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11410000</td>\n",
       "      <td>7420</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      price  area  bedrooms  bathrooms  stories mainroad guestroom basement  \\\n",
       "0  13300000  7420         4          2        3      yes        no       no   \n",
       "1  12250000  8960         4          4        4      yes        no       no   \n",
       "2  12250000  9960         3          2        2      yes        no      yes   \n",
       "3  12215000  7500         4          2        2      yes        no      yes   \n",
       "4  11410000  7420         4          1        2      yes       yes      yes   \n",
       "\n",
       "  hotwaterheating airconditioning  parking prefarea furnishingstatus  \n",
       "0              no             yes        2      yes        furnished  \n",
       "1              no             yes        3       no        furnished  \n",
       "2              no              no        2      yes   semi-furnished  \n",
       "3              no             yes        3      yes        furnished  \n",
       "4              no             yes        2       no        furnished  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38074c03",
   "metadata": {},
   "source": [
    "# Preparing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bf34bc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data=datasets.load_iris()\n",
    "x=np.array(data[['area','bedrooms']][:2000])\n",
    "y=np.array(data['price'][:2000])\n",
    "# x,y,names=data['data'],data['target'],data[\"target_names\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "de862294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[7420,    4],\n",
       "        [8960,    4],\n",
       "        [9960,    3],\n",
       "        ...,\n",
       "        [3620,    2],\n",
       "        [2910,    3],\n",
       "        [3850,    3]]),\n",
       " array([13300000, 12250000, 12250000, 12215000, 11410000, 10850000,\n",
       "        10150000, 10150000,  9870000,  9800000,  9800000,  9681000,\n",
       "         9310000,  9240000,  9240000,  9100000,  9100000,  8960000,\n",
       "         8890000,  8855000,  8750000,  8680000,  8645000,  8645000,\n",
       "         8575000,  8540000,  8463000,  8400000,  8400000,  8400000,\n",
       "         8400000,  8400000,  8295000,  8190000,  8120000,  8080940,\n",
       "         8043000,  7980000,  7962500,  7910000,  7875000,  7840000,\n",
       "         7700000,  7700000,  7560000,  7560000,  7525000,  7490000,\n",
       "         7455000,  7420000,  7420000,  7420000,  7350000,  7350000,\n",
       "         7350000,  7350000,  7343000,  7245000,  7210000,  7210000,\n",
       "         7140000,  7070000,  7070000,  7035000,  7000000,  6930000,\n",
       "         6930000,  6895000,  6860000,  6790000,  6790000,  6755000,\n",
       "         6720000,  6685000,  6650000,  6650000,  6650000,  6650000,\n",
       "         6650000,  6650000,  6629000,  6615000,  6615000,  6580000,\n",
       "         6510000,  6510000,  6510000,  6475000,  6475000,  6440000,\n",
       "         6440000,  6419000,  6405000,  6300000,  6300000,  6300000,\n",
       "         6300000,  6300000,  6293000,  6265000,  6230000,  6230000,\n",
       "         6195000,  6195000,  6195000,  6160000,  6160000,  6125000,\n",
       "         6107500,  6090000,  6090000,  6090000,  6083000,  6083000,\n",
       "         6020000,  6020000,  6020000,  5950000,  5950000,  5950000,\n",
       "         5950000,  5950000,  5950000,  5950000,  5950000,  5943000,\n",
       "         5880000,  5880000,  5873000,  5873000,  5866000,  5810000,\n",
       "         5810000,  5810000,  5803000,  5775000,  5740000,  5740000,\n",
       "         5740000,  5740000,  5740000,  5652500,  5600000,  5600000,\n",
       "         5600000,  5600000,  5600000,  5600000,  5600000,  5600000,\n",
       "         5600000,  5565000,  5565000,  5530000,  5530000,  5530000,\n",
       "         5523000,  5495000,  5495000,  5460000,  5460000,  5460000,\n",
       "         5460000,  5425000,  5390000,  5383000,  5320000,  5285000,\n",
       "         5250000,  5250000,  5250000,  5250000,  5250000,  5250000,\n",
       "         5250000,  5250000,  5250000,  5243000,  5229000,  5215000,\n",
       "         5215000,  5215000,  5145000,  5145000,  5110000,  5110000,\n",
       "         5110000,  5110000,  5075000,  5040000,  5040000,  5040000,\n",
       "         5040000,  5033000,  5005000,  4970000,  4970000,  4956000,\n",
       "         4935000,  4907000,  4900000,  4900000,  4900000,  4900000,\n",
       "         4900000,  4900000,  4900000,  4900000,  4900000,  4900000,\n",
       "         4900000,  4900000,  4893000,  4893000,  4865000,  4830000,\n",
       "         4830000,  4830000,  4830000,  4795000,  4795000,  4767000,\n",
       "         4760000,  4760000,  4760000,  4753000,  4690000,  4690000,\n",
       "         4690000,  4690000,  4690000,  4690000,  4655000,  4620000,\n",
       "         4620000,  4620000,  4620000,  4620000,  4613000,  4585000,\n",
       "         4585000,  4550000,  4550000,  4550000,  4550000,  4550000,\n",
       "         4550000,  4550000,  4543000,  4543000,  4515000,  4515000,\n",
       "         4515000,  4515000,  4480000,  4480000,  4480000,  4480000,\n",
       "         4480000,  4473000,  4473000,  4473000,  4445000,  4410000,\n",
       "         4410000,  4403000,  4403000,  4403000,  4382000,  4375000,\n",
       "         4340000,  4340000,  4340000,  4340000,  4340000,  4319000,\n",
       "         4305000,  4305000,  4277000,  4270000,  4270000,  4270000,\n",
       "         4270000,  4270000,  4270000,  4235000,  4235000,  4200000,\n",
       "         4200000,  4200000,  4200000,  4200000,  4200000,  4200000,\n",
       "         4200000,  4200000,  4200000,  4200000,  4200000,  4200000,\n",
       "         4200000,  4200000,  4200000,  4200000,  4193000,  4193000,\n",
       "         4165000,  4165000,  4165000,  4130000,  4130000,  4123000,\n",
       "         4098500,  4095000,  4095000,  4095000,  4060000,  4060000,\n",
       "         4060000,  4060000,  4060000,  4025000,  4025000,  4025000,\n",
       "         4007500,  4007500,  3990000,  3990000,  3990000,  3990000,\n",
       "         3990000,  3920000,  3920000,  3920000,  3920000,  3920000,\n",
       "         3920000,  3920000,  3885000,  3885000,  3850000,  3850000,\n",
       "         3850000,  3850000,  3850000,  3850000,  3850000,  3836000,\n",
       "         3815000,  3780000,  3780000,  3780000,  3780000,  3780000,\n",
       "         3780000,  3773000,  3773000,  3773000,  3745000,  3710000,\n",
       "         3710000,  3710000,  3710000,  3710000,  3703000,  3703000,\n",
       "         3675000,  3675000,  3675000,  3675000,  3640000,  3640000,\n",
       "         3640000,  3640000,  3640000,  3640000,  3640000,  3640000,\n",
       "         3640000,  3633000,  3605000,  3605000,  3570000,  3570000,\n",
       "         3570000,  3570000,  3535000,  3500000,  3500000,  3500000,\n",
       "         3500000,  3500000,  3500000,  3500000,  3500000,  3500000,\n",
       "         3500000,  3500000,  3500000,  3500000,  3500000,  3500000,\n",
       "         3500000,  3500000,  3493000,  3465000,  3465000,  3465000,\n",
       "         3430000,  3430000,  3430000,  3430000,  3430000,  3430000,\n",
       "         3423000,  3395000,  3395000,  3395000,  3360000,  3360000,\n",
       "         3360000,  3360000,  3360000,  3360000,  3360000,  3360000,\n",
       "         3353000,  3332000,  3325000,  3325000,  3290000,  3290000,\n",
       "         3290000,  3290000,  3290000,  3290000,  3290000,  3290000,\n",
       "         3255000,  3255000,  3234000,  3220000,  3220000,  3220000,\n",
       "         3220000,  3150000,  3150000,  3150000,  3150000,  3150000,\n",
       "         3150000,  3150000,  3150000,  3150000,  3143000,  3129000,\n",
       "         3118850,  3115000,  3115000,  3115000,  3087000,  3080000,\n",
       "         3080000,  3080000,  3080000,  3045000,  3010000,  3010000,\n",
       "         3010000,  3010000,  3010000,  3010000,  3010000,  3003000,\n",
       "         2975000,  2961000,  2940000,  2940000,  2940000,  2940000,\n",
       "         2940000,  2940000,  2940000,  2940000,  2870000,  2870000,\n",
       "         2870000,  2870000,  2852500,  2835000,  2835000,  2835000,\n",
       "         2800000,  2800000,  2730000,  2730000,  2695000,  2660000,\n",
       "         2660000,  2660000,  2660000,  2660000,  2660000,  2660000,\n",
       "         2653000,  2653000,  2604000,  2590000,  2590000,  2590000,\n",
       "         2520000,  2520000,  2520000,  2485000,  2485000,  2450000,\n",
       "         2450000,  2450000,  2450000,  2450000,  2450000,  2408000,\n",
       "         2380000,  2380000,  2380000,  2345000,  2310000,  2275000,\n",
       "         2275000,  2275000,  2240000,  2233000,  2135000,  2100000,\n",
       "         2100000,  2100000,  1960000,  1890000,  1890000,  1855000,\n",
       "         1820000,  1767150,  1750000,  1750000,  1750000]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2af90f6",
   "metadata": {},
   "source": [
    "# Splitting the Dataset into Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a1fab90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "22a37108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56007ef",
   "metadata": {},
   "source": [
    "# Training the Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cc096c6e",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 3745000 is out of bounds for axis 1 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m a\u001b[38;5;241m=\u001b[39mNeuralNetwork()\n\u001b[1;32m----> 2\u001b[0m \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0.0001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m50000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[29], line 63\u001b[0m, in \u001b[0;36mNeuralNetwork.train\u001b[1;34m(self, X, y, layers, neurons, LR, iterations, loss_time)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(iterations):\n\u001b[0;32m     62\u001b[0m     OUT\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(X)\n\u001b[1;32m---> 63\u001b[0m     DERR\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43mOUT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackward(LR,DERR)\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlocal_derivatives\u001b[38;5;241m=\u001b[39m[]            \u001b[38;5;66;03m# empty local derivatives to calculate them again\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[29], line 38\u001b[0m, in \u001b[0;36mNeuralNetwork.loss\u001b[1;34m(self, y, outputs)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss\u001b[39m(\u001b[38;5;28mself\u001b[39m,y,outputs):\n\u001b[1;32m---> 38\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mderivative_table\u001b[38;5;241m=\u001b[39moutputs\u001b[38;5;241m-\u001b[39m\u001b[43moutputs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mderivative_table[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mderivative_table\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_loss\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mderivative_table)\n",
      "\u001b[1;31mIndexError\u001b[0m: index 3745000 is out of bounds for axis 1 with size 1"
     ]
    }
   ],
   "source": [
    "a=NeuralNetwork()\n",
    "a.train(x_train,y_train,3,[5,7,1],0.0001,50000,1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2d7557",
   "metadata": {},
   "source": [
    "# Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38027cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93.33333333333333\n"
     ]
    }
   ],
   "source": [
    "a.test(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "898b675c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('model.pkl', 'wb') as outp:  # Overwrites any existing file.\n",
    "        pickle.dump(a, outp, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0b853d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
